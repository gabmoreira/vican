{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Pose estimation of camera networks</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from cam import *\n",
    "from pgo import *\n",
    "from plot import *\n",
    "from linalg import *\n",
    "from dataset import Dataset\n",
    "\n",
    "# Edit path to the folder containing the renders\n",
    "RENDER_PATH = \"./small_room_render\"\n",
    "# Edit path to the folder containing the cube calibration images.\n",
    "OBJ_RENDER_PATH = \"./cube_calib_render/\"\n",
    "# Edit marker size (in meters) check render script to be sure\n",
    "MARKER_SIZE = 0.47 * 0.575\n",
    "# Check which IDs are used \n",
    "MARKER_IDS = list(map(str, range(24)))\n",
    "\n",
    "dataset     = Dataset(root=RENDER_PATH)\n",
    "obj_dataset = Dataset(root=OBJ_RENDER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calibrate cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Marker detection\n",
      "Received 777 images.\n",
      "Started pool of 96 workers.\n",
      "Merging dictionaries...\n",
      "Found markers in 777 images\n",
      "Finished: 6234 markers detected.\n",
      "\n",
      "----------------* PGO *----------------\n",
      "Received 5390 edges.\n",
      "Total of 799 nodes.\n",
      "Final graph is connected.\n",
      "\t799 nodes\n",
      "\t5390 edges\n",
      "Building SO(3) sparse block-matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba85a30c401a42f787c3feb2aad6fa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSO(3) Eigenvalues: [6.1845071e-06 6.8076492e-06 8.2665711e-06 1.2621890e-01 1.2621886e-01]\n",
      "\tSO(3) Eigengap:    1.527e+04\n",
      "Building SO(3) sparse block-matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae8892201b643a99c34ff44803d77c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Edit noise model here\n",
    "k_r = lambda t : np.exp( -1.0 * np.linalg.norm(t, ord=2) )\n",
    "k_t = lambda t : np.exp( -1.0 * np.linalg.norm(t, ord=2) )\n",
    "\n",
    "aux = estimate_pose_mp(cams=obj_dataset.im_data['cam'],\n",
    "                       im_filenames=obj_dataset.im_data['filename'],\n",
    "                       aruco='DICT_4X4_1000',\n",
    "                       marker_size=MARKER_SIZE,\n",
    "                       corner_refine='CORNER_REFINE_APRILTAG',\n",
    "                       marker_ids=MARKER_IDS,\n",
    "                       flags='SOLVEPNP_IPPE_SQUARE',\n",
    "                       brightness=-120,\n",
    "                       contrast=120)\n",
    "\n",
    "aux = {k:v for k,v in aux.items() if v['reprojected_err'] < 0.1}\n",
    "\n",
    "cam_cube_edges = {}\n",
    "for k, v in aux.items():\n",
    "    v['k_r'] = k_r(v['pose'].t())\n",
    "    v['k_t'] = k_t(v['pose'].t())\n",
    "    cam_cube_edges['c' + k[0], k[1].split('_')[-1]] = v\n",
    "\n",
    "pgo = PGO(edges=cam_cube_edges, dtype=np.float32)\n",
    "cube_pose_est = pgo.optimize()\n",
    "cube_pose_est = {k : v for k,v in cube_pose_est.items() if k[0][0] != 'c'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Detect markers, estimate camera-marker pose through P4P\n",
    "**cam_marker_edges** is a dictionary where each key is a tuple (str: node, str: node) and the value is a dictionary with keys _'pose'_, _'corners'_, _'reprojected_err'_, _'im_filename'_. Alternatively load a previous file to avoid computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Marker detection\n",
      "Received 77307 images.\n",
      "Started pool of 96 workers.\n",
      "Merging dictionaries...\n",
      "Found markers in 77130 images\n",
      "Finished: 473214 markers detected.\n"
     ]
    }
   ],
   "source": [
    "cam_marker_edges = estimate_pose_mp(cams=dataset.im_data['cam'],\n",
    "                                    im_filenames=dataset.im_data['filename'],\n",
    "                                    aruco='DICT_4X4_1000',\n",
    "                                    marker_size=MARKER_SIZE,\n",
    "                                    corner_refine='CORNER_REFINE_APRILTAG',\n",
    "                                    marker_ids=MARKER_IDS,\n",
    "                                    flags='SOLVEPNP_IPPE_SQUARE',\n",
    "                                    brightness=-120,\n",
    "                                    contrast=120)\n",
    "\n",
    "torch.save(cam_marker_edges, os.path.join(RENDER_PATH, './cam_marker_edges.pt'))\n",
    "#cam_marker_edges = torch.load(os.path.join(RENDER_PATH, './cam_marker_edges.pt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received graph with 91017 nodes 356735 edges\n",
      "Applying constraints (5.017s).\n",
      "Bipartite graph: 25 cameras, 4999 timesteps, 49958 edges.\n",
      "Building 25x4999 adjacency and 75x14997 SO(3) sparse matrices (0.665s).\n",
      "Building power graph (0.092s).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d877d1bfbdf24ffbb0835811051ffd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sparse 409866x15072 incidence matrix (14.923s).\n",
      "Solving sparse linear system (1.166s).\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Select a subset of timesteps\n",
    "edges = {k : v for k, v in cam_marker_edges.items() if int(k[1].split('_')[0]) < 5000}\n",
    "\n",
    "pose_est = bipartite_se3sync(edges,\n",
    "                             constraints=cube_pose_est,\n",
    "                             noise_model_r=lambda pose : np.exp(-1.5 * np.linalg.norm(pose.t(), ord=2)),\n",
    "                             noise_model_t=lambda pose : np.exp(-1.0 * np.linalg.norm(pose.t(), ord=2)), # use -1.0 for small room\n",
    "                             edge_filter=lambda edge : edge['reprojected_err'] < 0.05,\n",
    "                             maxiter=3,\n",
    "                             lsqr_solver=\"conjugate_gradient\",\n",
    "                             dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Numeric results: comparison with ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO(3)\t min: 0.000deg  |  avg: 0.051deg  |  median: 0.056deg  |  max: 0.093deg\n",
      "E(3) \t min: 3.235cm   |  avg: 24.376cm   |  median: 32.062cm   |  max: 44.623cm\n",
      "Missing cam IDs: []\n"
     ]
    }
   ],
   "source": [
    "missing_cam_ids = [c for c in dataset.cams.keys() if c not in pose_est.keys()]\n",
    "valid_cam_ids   = [c for c in dataset.cams.keys() if c in pose_est.keys()]\n",
    "\n",
    "G = optimize_gauge_SE3([dataset.cams[c].extrinsics.inv() for c in valid_cam_ids],\n",
    "                       [pose_est[c] for c in valid_cam_ids])\n",
    "r_err  = []\n",
    "t_err  = []\n",
    "for c in valid_cam_ids:\n",
    "    gt  = dataset.cams[c].extrinsics.inv()\n",
    "    est = pose_est[c] @ G\n",
    "    t_err.append(np.linalg.norm(gt.t() - est.t(), ord=2)*100)\n",
    "    r_err.append(distance_SO3(gt.R(), est.R()))              \n",
    "\n",
    "print(\"SO(3)\\t min: {:.3f}deg  |  avg: {:.3f}deg  |  median: {:.3f}deg  |  max: {:.3f}deg\".format(np.min(r_err), np.mean(r_err), np.median(r_err), np.max(r_err)))\n",
    "print(\"E(3) \\t min: {:.3f}cm   |  avg: {:.3f}cm   |  median: {:.3f}cm   |  max: {:.3f}cm\".format(np.min(t_err), np.mean(t_err), np.median(t_err), np.max(t_err)))\n",
    "print(\"Missing cam IDs: {}\".format(missing_cam_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Top-down XY view plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "lgd = []\n",
    "\n",
    "xy_est = []\n",
    "for n in valid_cam_ids:\n",
    "    est = (pose_est[n] @ G).inv().t()\n",
    "    xy_est.append(est[:2])\n",
    "xy_est = np.stack(xy_est, axis=0)\n",
    "plt.scatter(xy_est[:,0], xy_est[:,1], 10, marker='x', c='blue')\n",
    "lgd.append(\"Estimated cameras ({})\".format(len(valid_cam_ids)))\n",
    "\n",
    "xy_gt = []\n",
    "for n in dataset.cams.keys():\n",
    "    gt = dataset.cams[n].extrinsics.t()\n",
    "    xy_gt.append(gt[:2])\n",
    "xy_gt = np.stack(xy_gt, axis=0)\n",
    "plt.scatter(xy_gt[:,0],  xy_gt[:,1],  10, marker='^', c='green')\n",
    "lgd.append(\"Ground-truth cameras ({})\".format(len(cams)))\n",
    "\n",
    "\n",
    "xy_t = []\n",
    "for i in range(8):\n",
    "    with open(os.path.join(RENDER_PATH, 'aruco_cube_pose_{}.json').format(i)) as f:\n",
    "        markers = json.load(f)\n",
    "    for v in markers.values():\n",
    "        xy_t.append(v['t'][:2])\n",
    "xy_t = np.stack(xy_t, axis=0)\n",
    "plt.scatter(xy_t[:,0],   xy_t[:,1],  10, marker='s', c=[1,0,0,0.2])\n",
    "lgd.append(\"Object ({})\".format(len(xy_t)))\n",
    "\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x (m)')\n",
    "plt.ylabel('y (m)')\n",
    "plt.legend(lgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
