{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> VICAN: Tutorial</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from vican.cam import estimate_pose_mp\n",
    "from vican.bipgo import bipartite_se3sync, object_bipartite_se3sync\n",
    "from vican.plot import plot2D\n",
    "from vican.geometry import optimize_gauge_SE3, distance_SO3, angle\n",
    "from vican.dataset import Dataset\n",
    "\n",
    "# Edit path to the folder containing the renders\n",
    "DATASET_PATH = \"./small_room\"\n",
    "# Edit path to the folder containing the cube calibration images.\n",
    "OBJ_DATASET_PATH = \"./cube_calib\"\n",
    "# Edit marker size in meters\n",
    "MARKER_SIZE = 0.48 * 0.575\n",
    "# Check which IDs are used \n",
    "MARKER_IDS = list(map(str, range(24)))\n",
    "\n",
    "dataset     = Dataset(root=DATASET_PATH)\n",
    "obj_dataset = Dataset(root=OBJ_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calibrate object: cube with 24 markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will compute camera-marker edges via PnP, in parallel\n",
    "aux = estimate_pose_mp(cams=obj_dataset.im_data['cam'],\n",
    "                       im_filenames=obj_dataset.im_data['filename'],\n",
    "                       aruco='DICT_4X4_1000',\n",
    "                       marker_size=MARKER_SIZE,\n",
    "                       corner_refine='CORNER_REFINE_APRILTAG',\n",
    "                       marker_ids=MARKER_IDS,\n",
    "                       flags='SOLVEPNP_IPPE_SQUARE',\n",
    "                       brightness=-150,\n",
    "                       contrast=120)\n",
    "\n",
    "# Save it to use later, if necessary\n",
    "torch.save(aux, os.path.join(OBJ_DATASET_PATH, 'cam_marker_edges.pt'))\n",
    "\n",
    "# Alternatively, comment the code above and load already precomputed edges\n",
    "#aux = torch.load(os.path.join(OBJ_DATASET_PATH, 'cam_marker_edges.pt'))\n",
    "\n",
    "# Optimization - see extended paper\n",
    "obj_pose_est = object_bipartite_se3sync(aux,\n",
    "                                        noise_model_r=lambda edge : 0.01 * Polygon(zip(edge['corners'][:,0], edge['corners'][:,1])).area**2,\n",
    "                                        noise_model_t=lambda edge : 0.001 * Polygon(zip(edge['corners'][:,0], edge['corners'][:,1])).area**6,\n",
    "                                        edge_filter=lambda edge : edge['reprojected_err'] < 0.1,\n",
    "                                        maxiter=4,\n",
    "                                        lsqr_solver=\"conjugate_gradient\",\n",
    "                                        dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Detect markers & estimate camera-marker poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will compute camera-marker edges via PnP, in parallel\n",
    "cam_marker_edges = estimate_pose_mp(cams=dataset.im_data['cam'],\n",
    "                                    im_filenames=dataset.im_data['filename'],\n",
    "                                    aruco='DICT_4X4_1000',\n",
    "                                    marker_size=MARKER_SIZE,\n",
    "                                    corner_refine='CORNER_REFINE_APRILTAG',\n",
    "                                    marker_ids=MARKER_IDS,\n",
    "                                    flags='SOLVEPNP_IPPE_SQUARE',\n",
    "                                    brightness=-150,\n",
    "                                    contrast=120)\n",
    "\n",
    "# Save it to use later, if necessary\n",
    "torch.save(cam_marker_edges, os.path.join(DATASET_PATH, 'cam_marker_edges.pt'))\n",
    "\n",
    "# Alternatively, comment the code above and load already precomputed edges\n",
    "# cam_marker_edges = torch.load(os.path.join(RENDER_PATH, 'cam_marker_edges.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of timesteps\n",
    "tmax  = 2000\n",
    "edges = {k : v for k, v in cam_marker_edges.items() if int(k[1].split('_')[0]) < tmax}\n",
    "\n",
    "# Optimization - see extended paper\n",
    "pose_est = bipartite_se3sync(edges,\n",
    "                             constraints=obj_pose_est,\n",
    "                             noise_model_r=lambda edge : 0.001 * Polygon(zip(edge['corners'][:,0], edge['corners'][:,1])).area**1.0,\n",
    "                             noise_model_t=lambda edge : 0.001 * Polygon(zip(edge['corners'][:,0], edge['corners'][:,1])).area**2.0,\n",
    "                             edge_filter=lambda edge : edge['reprojected_err'] < 0.05,\n",
    "                             maxiter=4,\n",
    "                             lsqr_solver=\"conjugate_gradient\",\n",
    "                             dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comparison with ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cam_ids = [c for c in dataset.cams.keys() if c not in pose_est.keys()]\n",
    "valid_cam_ids   = [c for c in dataset.cams.keys() if c in pose_est.keys()]\n",
    "\n",
    "# Compute gauge symmetry in order to compare \n",
    "G = optimize_gauge_SE3([dataset.cams[c].extrinsics.inv() for c in valid_cam_ids],\n",
    "                       [pose_est[c].inv() for c in valid_cam_ids])\n",
    "\n",
    "r_err, t_err = [], []\n",
    "x_err, y_err, z_err = [], [], []\n",
    "\n",
    "for c in valid_cam_ids:\n",
    "    gt  = dataset.cams[c].extrinsics\n",
    "    est = G.inv() @ pose_est[c]\n",
    "    t_err.append(np.linalg.norm(gt.t() - est.t(), ord=2)*100)\n",
    "    r_err.append(distance_SO3(gt.R(), est.R()))              \n",
    "    x_err.append(abs(gt.t()[0] - est.t()[0])*100)\n",
    "    y_err.append(abs(gt.t()[1] - est.t()[1])*100)\n",
    "    z_err.append(abs(gt.t()[2] - est.t()[2])*100)\n",
    "\n",
    "print(\"Missing cameras: {}\".format(missing_cam_ids if len(missing_cam_ids) > 0 else \"None\"))\n",
    "print(\"SO(3)\\t min: {:.3f}deg | avg: {:.3f}deg | std: {:.3f}cm |  median: {:.3f}deg |  max: {:.3f}deg\".format(np.min(r_err), np.mean(r_err), np.std(r_err), np.median(r_err), np.max(r_err)))\n",
    "print(\"E(3) \\t min: {:.3f}cm  | avg: {:.3f}cm  | std: {:.3f}cm |  median: {:.3f}cm  |  max: {:.3f}cm\".format(np.min(t_err), np.mean(t_err), np.std(t_err), np.median(t_err), np.max(t_err)))\n",
    "print(\"X \\t min: {:.3f}cm  | avg: {:.3f}cm  | std: {:.3f}cm |  median: {:.3f}cm  |  max: {:.3f}cm\".format(np.min(x_err), np.mean(x_err), np.std(x_err), np.median(x_err), np.max(x_err)))\n",
    "print(\"Y \\t min: {:.3f}cm  | avg: {:.3f}cm  | std: {:.3f}cm |  median: {:.3f}cm  |  max: {:.3f}cm\".format(np.min(y_err), np.mean(y_err), np.std(y_err), np.median(y_err), np.max(y_err)))\n",
    "print(\"Z \\t min: {:.3f}cm  | avg: {:.3f}cm  | std: {:.3f}cm |  median: {:.3f}cm  |  max: {:.3f}cm\".format(np.min(z_err), np.mean(z_err), np.std(z_err), np.median(z_err), np.max(z_err)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(14,14))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plot2D(ax, pose_est, idx=valid_cam_ids, left_gauge=G.inv(), view='xy', marker='x', s=30, c='blue')\n",
    "plot2D(ax, dataset.cams, view='xy', marker='x', s=30, c='red')\n",
    "plot2D(ax, dataset.object, view='xy', marker='.', s=15, c=[0,0.6,0,0.4])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x (m)')\n",
    "plt.ylabel('y (m)')\n",
    "plt.legend(['Estimates', 'Ground-truth', 'Object'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
